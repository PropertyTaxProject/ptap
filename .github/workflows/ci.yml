name: CI

env:
  POETRY_VIRTUALENVS_IN_PROJECT: true

permissions:
  id-token: write
  contents: read

on:
  pull_request:
    types: [opened, synchronized]
  push:
  workflow_dispatch:

jobs:
  python-checks:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v2

      - run: pipx install poetry

      - uses: actions/setup-python@v4
        id: py
        with:
          python-version: 3.11
          cache: poetry

      - run: poetry install --no-interaction

      - run: poetry run black . --check

      - run: poetry run ruff check .

  js-checks:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v2

      - uses: actions/setup-node@v1
        with:
          node-version: "17.x"

      - uses: actions/cache@v1
        with:
          path: ~/.npm
          key: npm-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            npm-

      - run: npm ci --prefer-offline --no-audit --no-optional

      - run: npm run lint

      - run: npm run prettier

      - run: npm run build

  cypress:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: kartoza/postgis:13.0
        env:
          POSTGRES_USER: ptap
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: ptap
        ports:
          # will assign a random free host port
          - 5432/tcp
        # needed because the postgres container does not provide a healthcheck
        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 5

    steps:
      - uses: actions/checkout@v2

      - run: pipx install poetry

      - uses: actions/setup-python@v4
        id: py
        with:
          python-version: 3.11
          cache: poetry

      - run: poetry install --no-interaction

      - uses: actions/setup-node@v1
        with:
          node-version: "17.x"

      - uses: actions/cache@v1
        with:
          path: ~/.npm
          key: npm-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            npm-

      - run: npm ci --prefer-offline --no-audit --no-optional

      - run: npx cypress install

      - name: Install GDAL dependencies
        run: sudo apt-get update -y && sudo apt-get install -y gdal-bin

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ vars.AWS_ACCOUNT_ID }}:role/ptap-terraform-github-role
          aws-region: us-east-1

      - name: Download and restore database
        env:
          S3_BUCKET: ${{ vars.S3_BUCKET }}
          DATABASE_URL: postgresql://ptap:postgres@localhost:${{ job.services.postgres.ports[5432] }}/ptap
        run: |
          make download-data
          make restore

      - uses: cypress-io/github-action@v4.1.0
        env:
          DATABASE_URL: postgresql://ptap:postgres@localhost:${{ job.services.postgres.ports[5432] }}/ptap
        with:
          config-file: cypress.config.js
          build: npm run build
          start: make start-py
          wait-on: "http://localhost:5000"
          wait-on-timeout: 60
          browser: chrome
          headless: true

      - uses: actions/upload-artifact@v3
        if: failure()
        with:
          name: cypress-screenshots
          path: cypress/screenshots
          if-no-files-found: ignore

      - uses: actions/upload-artifact@v3
        if: failure()
        with:
          name: cypress-videos
          path: cypress/videos
          if-no-files-found: ignore

  deploy:
    # needs: [python-checks, js-checks, cypress]
    # TODO:
    # if: github.ref == 'refs/heads/master' && github.event_name == 'push'
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v2

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ vars.AWS_ACCOUNT_ID }}:role/ptap-terraform-github-role
          aws-region: us-east-1

      - uses: actions/setup-node@v1
        with:
          node-version: "17.x"

      - uses: actions/cache@v1
        with:
          path: ~/.npm
          key: npm-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            npm-

      - name: Build assets for production
        env:
          S3_BUCKET: ${{ vars.S3_BUCKET }}
          PUBLIC_URL: https://${{ vars.S3_BUCKET }}.s3.amazonaws.com
        run: |
          npm ci --prefer-offline --no-audit --no-optional
          npm run build

      - env:
          S3_BUCKET: ${{ vars.S3_BUCKET }}
        run: aws s3 cp ./build/ s3://$S3_BUCKET/ --cache-control no-cache --recursive

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Check if ECR image exists
        id: container-exists
        continue-on-error: true
        env:
          REPOSITORY: ptap
          IMAGE_TAG: ${{ github.sha }}
        run: aws ecr describe-images --repository-name=$REPOSITORY --image-ids=imageTag=$IMAGE_TAG

      - name: Build, tag, and push docker image to ECR
        if: steps.container-exists.outcome != 'success'
        env:
          REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          REPOSITORY: ptap
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker build -t $REGISTRY/$REPOSITORY:$IMAGE_TAG .
          docker push $REGISTRY/$REPOSITORY:$IMAGE_TAG

      - uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.1.7

      - name: Update Lambda with Terraform
        working-directory: ./tf
        env:
          TF_VAR_lambda_image_tag: ${{ github.sha }}
        run: |
          terraform init
          terraform apply -auto-approve
